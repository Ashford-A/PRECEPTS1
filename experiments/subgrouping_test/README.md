# Testing the classification performance of oncogene mutation subgroupings #

In this experiment we train mutation classifiers to predict the presence of
subsets of genes' mutations in a tumor cohort. The characteristics of these
subgrouping classification models and especially their performances can then
be used to make inferences about the heterogeneity of downstream effects
caused by the mutations of a given cancer gene.

The results generated by this experiment form the basis of the paper

_"Systematic interrogation of mutation groupings reveals divergent downstream
expression programs within key cancer genes"_
**(MR Grzadkowski, HD Holly, J Somers, and E Demir)** 

currently under review for publication at BMC Bioinformatics. For the other
analyses used in this manuscript, see `../subgrouping_tour` and
`../subgrouping_thresholds`, both of which follow an analogous experiment
structure and identical setup steps.


## Preparing to run the experiment ##

Clone the `dryads-research` git repository into the current directory:

```git clone https://github.com/ohsu-comp-bio/dryads-research.git```

Install the `research` conda environment:

```conda env create -f environment.yml```

Register an account at https://www.synapse.org/; use your credentials to
create a file named `.synapseConfig` with the following format:
```
[authentication]
username: ...
password: ...
```

Create a directory for Broad Firehose datasets, and then download the
expression data for TCGA tumor cohorts using the command:

```
firehose_get_latest/firehose_get -tasks RSEM_genes_normalized stddata latest
```

Add a file named `data_locs.py` under `dryads-research/experiments/utilities`.
This file will contain the locations of datasets downloaded from various
repositories. Some of these files are available through our Open Science
Framework data repository (osf.io/gr24t/).

The following variables must be added:

```
# where Broad Firehose datasets were downloaded
firehose_dir = "/home/users/datasets/..."

# the local Synapse cache
syn_root = "..."

# where the METABRIC datasets were downloaded from cBioPortal
metabric_dir = "..."

# a directory to be used by VEP to store genome datasets
vep_cache_dir = "..."

# available at www.oncokb.org/cancerGenes or osf.io/2m47r
oncogene_list = ".../OncoKB_cancerGeneList.txt"

# list of molecular subtypes identified by PCAWG in TCGA cohorts
# available at osf.io/2m47r/
subtype_file = ".../tcga_subtypes.txt"
```

Make sure you have the following environment variables defined in your bash
environment:

 - *$CODEDIR* where the `dryads-research` repo was checked out
 - *$TEMPDIR* a temporary location for intermediate experiment output files
 - *$DATADIR* a permanent location for the final experiment output files



## Running the experiment ##

Use run_test.py to launch the experiment pipeline. Depending on the compute
cluster setup you are using, you will need to modify `cluster.json` which by
default is designed for Slurm.

Example usages of launching `run_test.py` in a Slurm compute environment
include:

 - running subgrouping tasks on the METABRIC(LumA) cohort using the
   Consequence->Exon mutation hierarchy, distributing subgrouping tasks among
   jobs submitted to the cluster such that each job takes no more than 250
   minutes:
```
 sbatch --mem-per-cpu=8000 --account='compbio' -c 4 --exclude=$ex_nodes \
    --output=$slurm_dir/subg-test.out --error=$slurm_dir/subg-test.err \
    dryads-research/experiments/subgrouping_test/run_tour.sh \
    -e microarray -t METABRIC_LumA \
    -s 20 -l Consequence__Exon -c Ridge -m 250 -r
```

 - running subgrouping tasks on the TCGA-BLCA cohort downloaded from Firehose
   using a mutation hierarchy based on genomic location, distributing
   subgrouping tasks such that each job runs for a maximum of 10 hours:
```
 sbatch --mem-per-cpu=8000 --account='compbio' -c 4 --exclude=$ex_nodes \
    --output=$slurm_dir/subg-test.out --error=$slurm_dir/subg-test.err \
    dryads-research/experiments/subgrouping_test/run_tour.sh \
    -e Firehose -t BLCA -s 20 -l Exon__Position__HGVSp -c Ridge -m 600 -r
```


## Analyzing the output of the experiment ##

Once an experiment is finished running, you should see output files saved in
the $DATADIR directory defined as above. Modules with names `plot_*.py` can be
used to generate plots of results generated from this output. Plots are by
default saved to the $DATADIR directory.

See `make_plots.sh` for examples of how to generate the set of plots used in
Grzadkowski et al.

